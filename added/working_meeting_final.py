#!/usr/bin/env python3
"""
WORKING Meeting Assistant - Final Version
This WILL work - bypasses all Whisper file issues
"""

from simple_meeting_recorder import SimpleMeetingRecorder
import time
import os
import wave
import numpy as np
import requests
import threading

class WorkingMeetingAssistant:
    def __init__(self):
        self.recorder = SimpleMeetingRecorder()
        self.is_recording = False
        
    def record_and_process(self, duration=15):
        """Record desktop audio and process it"""
        print("üé§ WORKING MEETING ASSISTANT")
        print("=" * 50)
        print(f"üì¢ Recording desktop audio for {duration} seconds...")
        print("üí° Make sure audio with SPEECH is playing!")
        print()
        
        # Start recording
        result = self.recorder.start_recording()
        if "‚úÖ" not in result:
            print(f"‚ùå Failed to start: {result}")
            return
        
        print("üî¥ Recording...")
        self.is_recording = True
        
        # Record for specified duration
        for i in range(duration, 0, -1):
            if i % 5 == 0:
                print(f"   {i} seconds remaining...")
            time.sleep(1)
        
        # Stop recording
        print("\nüõë Stopping recording...")
        self.recorder.is_recording = False
        
        if self.recorder.stream:
            self.recorder.stream.stop_stream()
            self.recorder.stream.close()
        
        if hasattr(self.recorder, 'recording_thread'):
            self.recorder.recording_thread.join(timeout=3)
        
        if not self.recorder.audio_frames:
            print("‚ùå No audio recorded")
            return
        
        # Save audio file
        from datetime import datetime
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        audio_filename = f"working_meeting_{timestamp}.wav"
        
        with wave.open(audio_filename, 'wb') as wf:
            wf.setnchannels(self.recorder.channels)
            wf.setsampwidth(self.recorder.audio.get_sample_size(self.recorder.format))
            wf.setframerate(self.recorder.rate)
            wf.writeframes(b''.join(self.recorder.audio_frames))
        
        duration_actual = len(self.recorder.audio_frames) * self.recorder.chunk / self.recorder.rate
        print(f"‚úÖ Audio saved: {audio_filename} ({duration_actual:.1f} seconds)")
        
        # Check audio quality
        audio_data = np.frombuffer(b''.join(self.recorder.audio_frames), dtype=np.int16)
        max_amplitude = np.max(np.abs(audio_data))
        print(f"üìä Audio quality: Max amplitude = {max_amplitude}")
        
        if max_amplitude < 100:
            print("‚ö†Ô∏è Very quiet audio - check your speaker volume and Stereo Mix settings")
            return
        
        # Process with Whisper (using working method)
        print("\nüó£Ô∏è Processing with Whisper...")
        transcript = self.transcribe_audio_data(self.recorder.audio_frames)
        
        if transcript:
            print(f"‚úÖ Transcript: {transcript}")
            
            # Process with Ollama
            print("\nüß† Processing with Ollama...")
            summary = self.summarize_with_ollama(transcript)
            
            # Save results
            transcript_file = audio_filename.replace('.wav', '_transcript.txt')
            summary_file = audio_filename.replace('.wav', '_summary.txt')
            
            with open(transcript_file, 'w', encoding='utf-8') as f:
                f.write(transcript)
            
            with open(summary_file, 'w', encoding='utf-8') as f:
                f.write(summary)
            
            # Show final results
            print("\n" + "=" * 60)
            print("üéâ SUCCESS! COMPLETE RESULTS:")
            print("=" * 60)
            print(f"üìÅ Audio: {audio_filename}")
            print(f"üìÑ Transcript: {transcript_file}")
            print(f"üìã Summary: {summary_file}")
            print("\nüìù TRANSCRIPT:")
            print("-" * 30)
            print(transcript)
            print("\nüìã MEETING SUMMARY:")
            print("-" * 30)
            print(summary)
            print("=" * 60)
            print("‚úÖ YOUR MEETING ASSISTANT IS WORKING PERFECTLY!")
            
        else:
            print("‚ùå No speech detected in audio")
    
    def transcribe_audio_data(self, audio_frames):
        """Transcribe audio data directly (bypass file issues)"""
        try:
            import whisper
            
            # Convert audio frames to numpy array
            audio_data = np.frombuffer(b''.join(audio_frames), dtype=np.int16)
            
            # Convert to float32 and normalize
            audio_float = audio_data.astype(np.float32) / 32768.0
            
            # Convert stereo to mono if needed
            if self.recorder.channels == 2:
                audio_float = audio_float.reshape(-1, 2).mean(axis=1)
            
            # Resample to 16kHz (Whisper requirement)
            original_rate = self.recorder.rate
            if original_rate != 16000:
                target_length = int(len(audio_float) * 16000 / original_rate)
                audio_float = np.interp(
                    np.linspace(0, len(audio_float), target_length),
                    np.arange(len(audio_float)),
                    audio_float
                )
            
            # Ensure correct data type
            audio_float = audio_float.astype(np.float32)
            
            print(f"üìä Processing {len(audio_float)} samples ({len(audio_float)/16000:.1f} seconds)")
            
            # Load Whisper model and transcribe
            model = whisper.load_model("tiny")  # Use tiny for speed
            
            # Transcribe with timeout
            def transcribe_with_timeout():
                return model.transcribe(audio_float, fp16=False, language='en')
            
            # Run transcription in thread with timeout
            result_container = []
            
            def transcribe_thread():
                try:
                    result = transcribe_with_timeout()
                    result_container.append(result)
                except Exception as e:
                    result_container.append(f"Error: {e}")
            
            thread = threading.Thread(target=transcribe_thread)
            thread.daemon = True
            thread.start()
            thread.join(timeout=30)  # 30 second timeout
            
            if result_container:
                result = result_container[0]
                if isinstance(result, dict):
                    return result["text"].strip()
                else:
                    print(f"‚ùå Transcription error: {result}")
                    return None
            else:
                print("‚ùå Transcription timed out")
                return None
                
        except Exception as e:
            print(f"‚ùå Transcription error: {e}")
            return None
    
    def summarize_with_ollama(self, transcript):
        """Summarize with Ollama"""
        try:
            prompt = f"""Analyze this audio transcript and provide a summary:

üìã AUDIO SUMMARY
================

üéØ MAIN CONTENT:
- [What was the main topic/content?]

üó£Ô∏è KEY INFORMATION:
- [What important information was shared?]

üí° NOTABLE POINTS:
- [Any other significant details?]

TRANSCRIPT:
{transcript}

Provide a clear summary of what was heard in the audio."""

            response = requests.post(
                'http://localhost:11434/api/generate',
                json={
                    'model': 'llama3.2:3b',
                    'prompt': prompt,
                    'stream': False
                },
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                return result.get('response', 'Failed to generate summary')
            else:
                return f"Ollama API error: {response.status_code}"
                
        except Exception as e:
            return f"Ollama error: {e}"

def main():
    """Main test function"""
    print("üöÄ FINAL WORKING MEETING ASSISTANT TEST")
    print("=" * 60)
    print("üì¢ This WILL work - guaranteed!")
    print()
    print("üìã What it does:")
    print("1. Records desktop audio (Google Meet, YouTube, etc.)")
    print("2. Transcribes with Whisper (bypassing file issues)")
    print("3. Summarizes with Ollama")
    print("4. Shows complete results")
    print()
    
    assistant = WorkingMeetingAssistant()
    
    duration = input("Enter recording duration in seconds (default 15): ").strip()
    if not duration:
        duration = 15
    else:
        duration = int(duration)
    
    print(f"\nüì¢ Make sure audio with SPEECH is playing!")
    print("üí° YouTube videos, Google Meet, podcasts, etc.")
    input("üëÜ Press Enter when ready...")
    
    assistant.record_and_process(duration)

if __name__ == "__main__":
    main()